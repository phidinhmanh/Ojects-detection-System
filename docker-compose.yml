# Docker Compose for local development
services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - API_DEBUG=true
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./data:/app/data
      - ./model:/app/model
    depends_on:
      - mlflow
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/api/v1/health" ]
      interval: 30s
      timeout: 10s
      retries: 3

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.2
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
    command: mlflow server --host 0.0.0.0 --backend-store-uri /mlruns

  # Optional: For running training jobs
  trainer:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./data:/app/data
      - ./model:/app/model
      - ./scripts:/app/scripts
    command: python scripts/train_model.py --epochs 5
    profiles:
      - training
    depends_on:
      - mlflow
